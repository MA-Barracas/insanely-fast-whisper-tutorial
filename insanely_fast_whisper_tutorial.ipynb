{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtl5mgQklbme0qf4q+pK/O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MA-Barracas/insanely-fast-whisper-tutorial/blob/main/insanely_fast_whisper_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hZ8-8Gd8CYMe"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade pip\n",
        "# !pip install --upgrade transformers datasets[audio] accelerate\n",
        "# !pip install --upgrade pytubefix pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "MwD3Mf2xCe07"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube  # Cambiado a pytubefix\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import traceback  # Importar el módulo traceback\n",
        "\n",
        "def descargar_audio_mp3(url):\n",
        "    try:\n",
        "        # Descarga del video\n",
        "        yt = YouTube(url)\n",
        "        video = yt.streams.filter(only_audio=True).first()\n",
        "        output_file = video.download()\n",
        "\n",
        "        # Conversión a MP3 usando pydub\n",
        "        mp3_filename = os.path.splitext(output_file)[0] + \".mp3\"\n",
        "        audio = AudioSegment.from_file(output_file)\n",
        "        audio.export(mp3_filename, format=\"mp3\")\n",
        "\n",
        "        # Eliminación del archivo original\n",
        "        os.remove(output_file)\n",
        "\n",
        "        print(f\"Archivo MP3 guardado como: {mp3_filename}\")\n",
        "        return mp3_filename\n",
        "    except Exception as e:\n",
        "        print(\"Ha ocurrido un error: \", e)\n",
        "        print(traceback.format_exc())\n",
        "        return mp3_filename\n",
        "\n",
        "# Ejemplo de uso\n",
        "url = \"https://www.youtube.com/watch?v=gqUQbjsYZLQ\"\n",
        "audi_filename = descargar_audio_mp3(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p-PuqWvPTUf",
        "outputId": "cbfc2378-595c-4cfa-c24a-e6c0dd38a0af"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo MP3 guardado como: /content/Cursor AI tutorial for beginners.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "W2B5JXfcD-5s"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "Z_EN8KHWEDab"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cBNTB0lE_8j",
        "outputId": "6aee8b6e-4779-44ac-b986-618414452af8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'y2mate.com - Cursor AI tutorial for beginners.mp3',\n",
              " 'Cursor AI tutorial for beginners.mp3',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(audi_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFdSBRyBEStB",
        "outputId": "79cf6625-87f9-4d81-8da6-5cf78bb087cc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len(result[\"text\"])"
      ],
      "metadata": {
        "id": "ox9Tek9xFF1o"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install cohere"
      ],
      "metadata": {
        "id": "PCtERhDnLIqd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "from google.colab import userdata\n",
        "co = cohere.Client(api_key=userdata.get('COHERE_API_KEY'))\n",
        "\n",
        "query = f\"\"\"\n",
        "Write a thorough summary for this text: '''\n",
        "{result[\"text\"]}\n",
        "'''\n",
        "Give extensive info about the content.\n",
        "Discuss all important points raised throughout.\n",
        "At the end, create a section of \"Conclusions\" and another for \"Summary\"\n",
        "\"\"\"\n",
        "\n",
        "cohere_query = co.chat(\n",
        "  model=\"command-r-plus\",\n",
        "  message=query\n",
        ")\n"
      ],
      "metadata": {
        "id": "DAd-fmnOEbEW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "display(Markdown(cohere_query.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "TMrqZy0oMbIK",
        "outputId": "1d42a53c-11a7-42db-9096-30fee276e99e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Text Summary\n\nIn this video, the host interviews Mike, a front-end developer who has been experimenting with Cursor AI. Mike shares his insights and best practices for getting the most out of Cursor AI and other similar tools. He emphasizes the importance of planning and having a developer mindset, even if one is not a developer. He suggests using tools like Figma or even just sketching ideas on paper before jumping into Cursor AI. He also introduces the concept of \"measure twice, cut once,\" which involves spending time planning and visualizing the project before starting to code.\n\nMike then introduces the idea of using V0, a UI library, to create wireframes and mock-ups before moving to Cursor AI. He demonstrates how V0 can help visualize the final product and provide a foundation for Cursor AI to build upon. He also mentions cursor.directory, a website that provides pre-written prompts for different technologies, which can be copied and pasted into Cursor AI to improve its performance.\n\nThe discussion moves on to the importance of tagging documentation (docs) within Cursor AI. Mike explains that by providing the AI with the latest and most accurate information, users can improve the accuracy of the code generated by Cursor AI. He also suggests asking other AI models for help when Cursor AI gets stuck, providing them with the bug, the attempted solutions, and the expected output.\n\nMike highlights the benefits of using AI for explaining and teaching code, adding comments, and duplicating existing functionality with a twist. He emphasizes the value of providing context to AI models and suggests using templates or starter kits to speed up the development process. He also mentions his own free starter kit, which includes boilerplate code for common features like authentication and database integration.\n\nThe interview concludes with a discussion about the potential future of AI models and the importance of investing time in learning and preparing for their advancements. Mike and the host agree that the best time to be a developer is now, as the combination of coding skills and AI tools will lead to powerful results.\n\n## Conclusions\n\nThis video offers valuable insights and best practices for anyone interested in using Cursor AI or similar AI tools for development. The key takeaways include the importance of planning, providing context, and utilizing additional resources such as V0, cursor.directory, and other AI models. By following these tips, users can improve the accuracy and efficiency of their AI-assisted development process.\n\n## Summary\n\nMike, a front-end developer, shares his best practices for using Cursor AI effectively. He emphasizes planning, using tools like V0 for wireframing, and providing context to AI models. He introduces cursor.directory for pre-written prompts and suggests tagging docs within Cursor AI. Mike highlights the benefits of AI for explaining code and suggests asking other AI models for help when stuck. He also recommends using templates and starter kits to speed up development. The discussion concludes with thoughts on the future of AI models and the importance of investing time in learning now."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.restart_runtime()\n"
      ],
      "metadata": {
        "id": "2UHYWngke_vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install insanely-fast-whisper"
      ],
      "metadata": {
        "id": "aG366b0sXJZ-"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q pipx && apt install python3.10-venv"
      ],
      "metadata": {
        "id": "jVvXK2axXKvg"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pipx run insanely-fast-whisper --file-name \"Cursor AI tutorial for beginners.mp3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWKtEvZ9avj4",
        "outputId": "d866ca35-a5fd-40ca-fba3-c40cef059421"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l⚠️  insanely-fast-whisper is already on your PATH and installed at\n",
            "    /usr/local/bin/insanely-fast-whisper. Downloading and running anyway.\n",
            "\u001b[2K🤗 \u001b[33mTranscribing...\u001b[0m \u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m \u001b[33m0:00:07\u001b[0mYou have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
            "\u001b[2K🤗 \u001b[33mTranscribing...\u001b[0m \u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m \u001b[33m0:00:12\u001b[0mPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "\u001b[2K🤗 \u001b[33mTranscribing...\u001b[0m \u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m \u001b[33m0:00:12\u001b[0mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[2K🤗 \u001b[33mTranscribing...\u001b[0m \u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m \u001b[33m0:01:39\u001b[0mWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "\u001b[2K🤗 \u001b[33mTranscribing...\u001b[0m \u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[37m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m\u001b[93m━\u001b[0m \u001b[33m0:01:39\u001b[0m\n",
            "\u001b[?25hVoila!✨ Your file has been transcribed go check it out over here 👉 output.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "text_ifw = json.load(open(\"output.json\", \"r\"))"
      ],
      "metadata": {
        "id": "hQLdGdH5WDNf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_ifw[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0Fci5OseZHN",
        "outputId": "ac3d74b4-c14c-4edc-efcb-e5263e42b377"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35661"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "from google.colab import userdata\n",
        "co = cohere.Client(api_key=userdata.get('COHERE_API_KEY'))\n",
        "query = f\"\"\"\n",
        "Write a thorough summary for this text: '''\n",
        "{text_ifw[\"text\"]}\n",
        "'''\n",
        "Give extensive info about the content.\n",
        "Discuss all important points raised throughout.\n",
        "At the end, create a section of \"Conclusions\" and another for \"Summary\"\n",
        "\"\"\"\n",
        "\n",
        "cohere_query = co.chat(\n",
        "  model=\"command-r-plus\",\n",
        "  message=query\n",
        ")\n",
        "\n",
        "from IPython.display import Markdown\n",
        "display(Markdown(cohere_query.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "vVlgJyZJeAln",
        "outputId": "ffb4afd0-d001-4c69-b42b-e552d2a1e04e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Text Summary\n\nIn this video interview, the host invites Mike, a front-end developer, to share his best practices and strategies for using Cursor AI effectively. Mike begins by emphasizing the importance of planning and having a developer mindset. He suggests using tools like Figma or even simple sketches to visualize the desired outcome before prompting AI models. He also introduces the concept of \"rubber ducking,\" where one explains their thoughts to a fictional duck, which helps with realizations and perspectives. \n\nMike then introduces the use of V0, a platform that assists in visualizing the minimum viable product (MVP) of an app or website. He demonstrates how V0 can be used to create a clean-looking marketplace website, emphasizing its ability to provide a nice-looking UI with the Shatsian UI library. He suggests spending a good amount of time on V0, making at least 10-15 prompts to get the desired outcome before moving on to Cursor AI.\n\nThe discussion turns to cursor.directory, a website that provides prompts which can be copied and pasted into the Cursor codebase. These prompts ensure that Cursor has the necessary context and information about the technologies being used, such as Next.js. Mike demonstrates how to create a .cursor rules file in the root of a project and the benefits of providing this additional context to Cursor. He also mentions that if a specific technology is not listed on cursor.directory, one can prompt AI models like Cloud or ChatGVT to write similar prompts.\n\nMike emphasizes the importance of tagging documentation (docs) for the technologies being used. He demonstrates how to add the Next.js and Supabase docs to Cursor and explains that having access to the latest and most accurate information helps Cursor provide better solutions. He suggests that users should treat the AI models as new employees and provide them with thorough onboarding, including relevant documentation.\n\nThe host and Mike discuss the benefit of asking other AI models for help when Cursor gets stuck. Mike shares his strategy of providing the bug, the attempted solutions, and the expected outcome to another AI model, resulting in improved results. They also touch on the value of explaining code and teaching concepts using AI, as well as adding comments to code for better understanding.\n\nMike highlights the importance of duplicating existing functionality when making similar changes and providing context to AI models. He suggests using templates or starter kits that include boilerplate code for common features like authentication and database integration, emphasizing that Cursor and other AI platforms will likely provide more templates in the future. He offers his own free starter kit as an example.\n\nThe interview concludes with a discussion about building social media apps using Cursor and the host's previous video on the topic. They encourage viewers to use the comment section for questions, discussions, and sharing their own experiences with Cursor and AI development.\n\n## Conclusions\n\nThe interview offers valuable insights and strategies for effectively using Cursor AI and similar tools. Planning, visualizing, and providing context are emphasized as key factors for successful outcomes. The host and Mike discuss the benefits of using V0 for initial planning and visualization, cursor.directory for providing technology-specific prompts, and tagging documentation for up-to-date information. Asking other AI models for help when Cursor gets stuck, explaining code, and using templates or starter kits are also highlighted as useful strategies.\n\n## Summary\n\nThe host interviews Mike, a front-end developer, to gain insights into best practices for using Cursor AI. Mike emphasizes planning, visualization, and providing context to AI models. He introduces V0 for initial planning and cursor.directory for technology-specific prompts. Tagging documentation and asking other AI models for help when stuck are recommended strategies. Explaining code, adding comments, and using templates are also discussed. Mike offers his own free starter kit as an example. The interview concludes with a discussion about building social media apps and engaging viewers through the comment section."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRr7SMrZfTZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}